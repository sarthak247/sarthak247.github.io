<!DOCTYPE html>
<html>

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta http-equiv="Accept-CH" content="DPR, Viewport-Width, Width">
<link rel="icon" href=./favicon.png type="image/gif">


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
      as="style"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
  <link
          href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
          rel="stylesheet">
</noscript>


<link rel="stylesheet" href="/css/font.css" media="all">



  


<meta property="og:url" content="http://localhost:1313/blogs/word-embeddings/">
  <meta property="og:site_name" content="Sarthak Thakur">
  <meta property="og:title" content="Unraveling the Power of Word Vectorization: From Text to Numbers">
  <meta property="og:description" content="Exploring and Unlocking Language for Machines: A Journey Through Various Word Vectorization Methods from classical methods like One-Hot Encoding to Modern Methods like Word2Vec">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2023-09-05T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-09-05T00:00:00+00:00">
    <meta property="article:tag" content="Vectorization">
    <meta property="article:tag" content="Embeddings">
    <meta property="article:tag" content="CountVectorizer">
    <meta property="article:tag" content="TF-IDF">
    <meta property="article:tag" content="Word2Vec">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Unraveling the Power of Word Vectorization: From Text to Numbers">
  <meta name="twitter:description" content="Exploring and Unlocking Language for Machines: A Journey Through Various Word Vectorization Methods from classical methods like One-Hot Encoding to Modern Methods like Word2Vec">


<link rel="stylesheet" href="/bootstrap-5/css/bootstrap.min.css" media="all"><link rel="stylesheet" href="/css/header.css" media="all">
<link rel="stylesheet" href="/css/footer.css" media="all">


<link rel="stylesheet" href="/css/theme.css" media="all">

<style>
    :root {
        --text-color: #343a40;
        --text-secondary-color: #6c757d;
        --background-color: #eaedf0;
        --secondary-background-color: #64ffda1a;
        --primary-color: #007bff;
        --secondary-color: #f8f9fa;

         
        --text-color-dark: #e4e6eb;
        --text-secondary-color-dark: #b0b3b8;
        --background-color-dark: #18191a;
        --secondary-background-color-dark: #212529;
        --primary-color-dark: #ffffff;
        --secondary-color-dark: #212529;
    }
    body {
        font-size: 1rem;
        font-weight: 400;
        line-height: 1.5;
        text-align: left;
    }

    html {
        background-color: var(--background-color) !important;
    }

    body::-webkit-scrollbar {
        height: 0px;
        width: 8px;
        background-color: var(--background-color);
    }

    ::-webkit-scrollbar-track {
        border-radius: 1rem;
    }

    ::-webkit-scrollbar-thumb {
        border-radius: 1rem;
        background: #b0b0b0;
        outline: 1px solid var(--background-color);
    }

    #search-content::-webkit-scrollbar {
        width: .5em;
        height: .1em;
        background-color: var(--background-color);
    }
</style>



<meta name="description" content="Exploring and Unlocking Language for Machines: A Journey Through Various Word Vectorization Methods from classical methods like One-Hot Encoding to Modern Methods like Word2Vec">
<link rel="stylesheet" href="/css/single.css">


<script defer src="/fontawesome-6/all-6.4.2.js"></script>


  
  

  <title>
Unraveling the Power of Word Vectorization: From Text to Numbers | Sarthak Thakur

  </title>
</head>

<body class="light">
  
  
<script>
    let localStorageValue = localStorage.getItem("pref-theme");
    let mediaQuery = window.matchMedia('(prefers-color-scheme: dark)').matches;

    switch (localStorageValue) {
        case "dark":
            document.body.classList.add('dark');
            break;
        case "light":
            document.body.classList.remove('dark');
            break;
        default:
            if (mediaQuery) {
                document.body.classList.add('dark');
            }
            break;
    }
</script>




<script>
    var prevScrollPos = window.pageYOffset;
    window.addEventListener("scroll", function showHeaderOnScroll() {
        let profileHeaderElem = document.getElementById("profileHeader");
        let currentScrollPos = window.pageYOffset;
        let resetHeaderStyle = false;
        let showNavBarOnScrollUp =  true ;
        let showNavBar = showNavBarOnScrollUp ? prevScrollPos > currentScrollPos : currentScrollPos > 0;
        if (showNavBar) {
            profileHeaderElem.classList.add("showHeaderOnTop");
        } else {
            resetHeaderStyle = true;
        }
        if(currentScrollPos === 0) {
            resetHeaderStyle = true;
        }
        if(resetHeaderStyle) {
            profileHeaderElem.classList.remove("showHeaderOnTop");
        }
        prevScrollPos = currentScrollPos;
    });
</script>



<header id="profileHeader">
    <nav class="pt-3 navbar navbar-expand-lg animate">
        <div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5">
            
            <a class="navbar-brand primary-font text-wrap" href="/">
                
                <img src="./favicon.png" width="30" height="30"
                    class="d-inline-block align-top">
                Sarthak Thakur
                
            </a>

            
                <div>
                    <input id="search" autocomplete="off" class="form-control mr-sm-2 d-none d-md-block" placeholder='Ctrl &#43; k to Search...'
                        aria-label="Search" oninput="searchOnChange(event)">
                </div>
            

            
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarContent"
                aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
                <svg aria-hidden="true" height="24" viewBox="0 0 16 16" version="1.1" width="24" data-view-component="true">
                    <path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path>
                </svg>
            </button>

            
            <div class="collapse navbar-collapse text-wrap primary-font" id="navbarContent">
                <ul class="navbar-nav ms-auto text-center">
                    
                        <li class="nav-item navbar-text d-block d-md-none">
                            <div class="nav-link">
                                <input id="search" autocomplete="off" class="form-control mr-sm-2" placeholder='Ctrl &#43; k to Search...' aria-label="Search" oninput="searchOnChange(event)">
                            </div>
                        </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#about" aria-label="about">
                            About Me
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#experience"
                            aria-label="experience">
                            Experience
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#education"
                            aria-label="education">
                            Education
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#projects"
                            aria-label="projects">
                            Projects
                        </a>
                    </li>
                    

                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#contact"
                            aria-label="contact">
                            Contact
                        </a>
                    </li>
                    

                    

                    
                    
                    
                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/blogs" title="Blog posts">
                            
                            Blog
                        </a>
                    </li>
                    
                    

                    
                    <li class="nav-item navbar-text">
                        
                        <div class="text-center">
                            <button id="theme-toggle">
                                <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                                </svg>
                                <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <circle cx="12" cy="12" r="5"></circle>
                                    <line x1="12" y1="1" x2="12" y2="3"></line>
                                    <line x1="12" y1="21" x2="12" y2="23"></line>
                                    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                                    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                                    <line x1="1" y1="12" x2="3" y2="12"></line>
                                    <line x1="21" y1="12" x2="23" y2="12"></line>
                                    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                                    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                                </svg>
                            </button>
                        </div>
                    </li>
                    

                </ul>

            </div>
        </div>
    </nav>
</header>
<div id="content">
<section id="single">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-sm-12 col-md-12 col-lg-9">
        <div class="pr-lg-4">
          <div class="title mb-5">
            <h1 class="text-center mb-4">Unraveling the Power of Word Vectorization: From Text to Numbers</h1>
            <div class="text-center">
              
              Sep 5, 2023

              
              <span id="readingTime">
                min read
              </span>
              
            </div>
          </div>
          
          <div class="featured-image">
            <img class="img-fluid mx-auto d-block" src="/blogs/word-embeddings/cover.png" alt="Unraveling the Power of Word Vectorization: From Text to Numbers">
          </div>
          
          <article class="page-content  p-2">
          <h2 id="introduction">Introduction</h2>
<p>In the realm of Natural Language Processing (NLP), one of the key challenges is to bridge the gap between the textual world of words and the numerical world of computers. We know that computers only understand in form of numbers (0s and 1s to be precise). So how do we make sense of human language words like maybe &ldquo;cat&rdquo; and &ldquo;car&rdquo; using algorithms and data structures? This is where <code>word vectorization</code> comes into play.</p>
<h2 id="why-do-we-need-word-vectorization">Why Do We Need Word Vectorization?</h2>
<p>One of my favourite books is &ldquo;Rich Dad, Poor Dad&rdquo; by Robert Kiyosaki. Now, whenever I pick up this book, I end up taking away something from it and learning something from it. But what if I wanted to process this book using a computer? For a computer, it&rsquo;s just a bunch of characters and symbols – meaningless patterns. Yet, this book contains knowledge, stories, and insights as we know already. It&rsquo;s written in a language, and those words convey meaning and context.</p>
<p>So, how do we make computers understand this intricate web of human communication? The answer lies in the art and science of word vectorization. In essence, word vectorization is the process of converting words into numerical vectors, allowing machines to grasp the semantics, relationships, and nuances hidden within text.</p>
<p>So for today, I started out to unravel the various methods used for word vectorization, starting with the classics like One-Hot Encoding, Count Vectorization (Bag of Words), and TF-IDF (Term Frequency-Inverse Document Frequency). I then ventured into the realm of Word2Vec, and was about to go through Glove as well but it was starting to become too much overwhelming for a day.</p>
<h2 id="one-hot-encoding">One-Hot Encoding</h2>
<p>To begin with, I started with the simplest method out there which was one-hot encoding. It takes each word in a given text and transforms it into a binary vector of 1s and 0s, where 1 means that a word is present in a sample and 0 means that it&rsquo;s not. To understand it, I started out with a simple example.</p>
<p>Let&rsquo;s consider the following three sentences:</p>
<table>
<thead>
<tr>
<th></th>
<th>Sample</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>I love coding and coding is fun</td>
</tr>
<tr>
<td>2.</td>
<td>Programming is fascinating</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define the sentences</span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;I love coding and coding is fun&#34;</span>, <span style="color:#e6db74">&#34;Programming is fascinating&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tokenize the sentences and build a vocabulary</span>
</span></span><span style="display:flex;"><span>vocabulary <span style="color:#f92672">=</span> set(word <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> sentence<span style="color:#f92672">.</span>lower()<span style="color:#f92672">.</span>split())
</span></span><span style="display:flex;"><span>vocabulary<span style="color:#f92672">.</span>remove(<span style="color:#e6db74">&#39;is&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame to display one-hot vectors</span>
</span></span><span style="display:flex;"><span>one_hot_vectors <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences:
</span></span><span style="display:flex;"><span>    one_hot_vector <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> sentence<span style="color:#f92672">.</span>lower()<span style="color:#f92672">.</span>split() <span style="color:#66d9ef">else</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> vocabulary]
</span></span><span style="display:flex;"><span>    one_hot_vectors<span style="color:#f92672">.</span>append(one_hot_vector)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(one_hot_vectors, columns<span style="color:#f92672">=</span>vocabulary, index <span style="color:#f92672">=</span> sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the DataFrame</span>
</span></span><span style="display:flex;"><span>print(df)
</span></span></code></pre></div><p>The output of the above code is as follows:</p>
<table>
<thead>
<tr>
<th></th>
<th>fascinating</th>
<th>coding</th>
<th>programming</th>
<th>fun</th>
<th>love</th>
</tr>
</thead>
<tbody>
<tr>
<td>I love coding and coding is fun</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Programming is fascinating</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>However, as simple and intuitive this method may seem like there are some associated pros and cons with it which is why it is not used much in modern practices.</p>
<h3 id="pros">Pros</h3>
<ol>
<li><strong>Simplicity</strong>:
<ul>
<li>One-Hot Encoding is straightforward to implement and understand, making it an excellent choice for basic text representation.</li>
</ul>
</li>
<li><strong>Independence</strong>:
<ul>
<li>Each word is represented independently, which can be useful in some machine learning models that assume feature independence.</li>
</ul>
</li>
</ol>
<h3 id="cons">Cons</h3>
<ol>
<li><strong>High Dimensionality</strong>:
<ul>
<li>With a large vocabulary, eg. the English vocabulary, the vectors become high-dimensional, which can be computationally expensive and memory-intensive.</li>
</ul>
</li>
<li><strong>Lack of semantics</strong>:
<ul>
<li>One-Hot Encoding doesn&rsquo;t capture any semantic relationships between words; all words are equidistant from each other in the vector space. It also doesn&rsquo;t keep any count or gives any relevance to how many times a word appears in a sentence as can be seen in our first example.</li>
</ul>
</li>
<li><strong>Sparsity</strong>:
<ul>
<li>As we move towards larger vocabularies, most elements in the one-hot vectors are zeros, leading to a sparse representation, which can be inefficient in terms of storage and computation.</li>
</ul>
</li>
</ol>
<p>Thus, although One-Hot Encoding serves as a good starting point it is almost impractical in today&rsquo;s machine learning requirements and thus we move forwards and explore some better methods like Count Vectorization and TF-IDF, which addressed some of these shortcomings if not all.</p>
<h2 id="countvectorzer-bag-of-words">CountVectorzer (Bag of Words):</h2>
<p>Moving forward, I read about the CountVectorizer or the Bag-of-Words model. In the realm of text representation, Count Vectorization, often referred to as the Bag of Words (BoW) model, takes a step beyond One-Hot Encoding. It not only acknowledges the presence or absence of words but also counts how many times each word appears in a document. This method creates a frequency-based numerical representation of text data, enabling machines to capture the importance of words based on their occurrence. We&rsquo;ll explore this method as well on our previously defined sample texts.</p>
<p><img src="bag_of_words.png" alt="Bag of Words"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a CountVectorizer instance</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the data</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get the feature names (vocabulary)</span>
</span></span><span style="display:flex;"><span>feature_names <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame to display count vectors</span>
</span></span><span style="display:flex;"><span>count_vectors <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(X<span style="color:#f92672">.</span>toarray(), columns<span style="color:#f92672">=</span>feature_names, index <span style="color:#f92672">=</span> sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the DataFrame</span>
</span></span><span style="display:flex;"><span>print(count_vectors)
</span></span></code></pre></div><p>The output of the above code will be as follows:</p>
<table>
<thead>
<tr>
<th></th>
<th>and</th>
<th>coding</th>
<th>fascinating</th>
<th>fun</th>
<th>is</th>
<th>love</th>
<th>programming</th>
</tr>
</thead>
<tbody>
<tr>
<td>I love coding and coding is fun</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>Programming is fascinating</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="pros-1">Pros</h3>
<ol>
<li><strong>Word Frequency</strong>:
<ul>
<li>Count Vectorization retains information about the frequency of words in a document, which can be valuable for tasks like text classification.</li>
</ul>
</li>
<li><strong>Simplicity</strong>:
<ul>
<li>Just like One Hot Encoding, BoW is also relatively simpler and serves as a good starting point for many NLP tasks.</li>
</ul>
</li>
</ol>
<h3 id="cons-1">Cons</h3>
<ol>
<li><strong>Lack of Semantics</strong>:
<ul>
<li>Similar to One-Hot Encoding, Count Vectorization doesn&rsquo;t capture semantic relationships between words, treating them as independent entities.</li>
</ul>
</li>
<li><strong>No word order</strong>:
<ul>
<li>It disregards the order of words in the document, which can be crucial for tasks like sentiment analysis or language modeling.</li>
</ul>
</li>
<li><strong>Vocabulary Size</strong>:
<ul>
<li>The vocabulary size can be significant, leading to large feature spaces and potential computational inefficiency for bigger vocabularies.</li>
</ul>
</li>
<li><strong>Sparsity</strong>:
<ul>
<li>Just like OHE, even BoW suffers from sparsity issues.</li>
</ul>
</li>
<li><strong>Stopwword Sensitivity</strong>:
<ul>
<li>Common words like &ldquo;the,&rdquo; &ldquo;and,&rdquo; and &ldquo;in&rdquo; can dominate the vector representation but may not carry meaningful information. A common practice is to first remove any stop words and then use BoW in order to make sure stopwords don&rsquo;t dominate our word vectors.</li>
</ul>
</li>
</ol>
<p>Thus, CountVectorizerorms a foundation for many text processing tasks, but it&rsquo;s essential to recognize its limitations, especially when dealing with tasks that require capturing semantic meaning and context.</p>
<h2 id="tf-idf">TF-IDF</h2>
<p>While going through different methods for word vectorization, I came around the realization that the above two methods do not consider the importance of a word in a corpus and consider all words equally. In the realm of text representation, TF-IDF is a method that goes beyond simple word counts like these previous methods. It stands for Term Frequency-Inverse Document Frequency and is designed to capture not only the frequency of words in a document but also their importance in the context of a corpus which is where previous methods like One-Hot and CountVectorizer fail as they treated all words equally. As a result, both of those methods cannot distinguish very common words or rare words. TF-IDF gives a measure that takes the importance of a word into consideration depending on how frequently it occurs in a document or corpus.</p>
<p>To understand TF-IDF, first we need to understand two terms:</p>
<ul>
<li><strong>Term Frequency (TF)</strong>: This component measures the frequency of a term (word) within a document. It rewards words that appear frequently within a document. It can be calculated as the ratio of the word&rsquo;s occurrences in a document to the total word count in that document.
l</li>
</ul>
$$TF(term)=\frac{\text{Number of times term appears in a document}}{\text{Total number of items in the document}}$$
<p>For example, consider our previous example <code>I love coding and coding is fun.</code> Here, TF(coding) is 1/6 as the word <code>and</code> has been ignored.</p>
<ul>
<li><strong>Inverse Document Frequeny</strong>: This component measures the rarity or importance of a word across all the documents. It is the log of the inverse of the document frequency where document frequency tells us the number of documents which contain a particular word.</li>
</ul>
$$DF(term)=\frac{\text{Documents containing our term}}{\text{Total number of documents}}$$
<p>Thus, DF tells us about the proportion of documents which contain our word of interest. Thus, we inverse it to make sure that the more common a word is, example stopwords, the less score it gets and a logarithm is taken to dampen or reduce it&rsquo;s effect on the final calculation.</p>
<!-- raw HTML omitted -->
$$IDF(term)=\log{\bigg(\frac{\text{Total number of documents}}{\text{Documents containing our term}}\bigg)}$$
<p>Thus, Inverse Document Frequency (IDF) is a measure of how unique or significant a word is across a collection of documents. It can be computed as the logarithm of the total number of documents divided by the number of documents in which the word occurs, effectively quantifying the word&rsquo;s rarity and importance in the entire document collection.</p>
<h3 id="pros-2">Pros</h3>
<ol>
<li>
<p><strong>Word Importance</strong>:</p>
<ul>
<li>TF-IDF captures the importance of words within specific documents and their significance in the broader corpus, making it suitable for tasks like text classification and information retrieval.</li>
</ul>
</li>
<li>
<p><strong>Weighting</strong>:</p>
<ul>
<li>It assigns weights to words based on their relevance, which can help algorithms focus on meaningful terms and disregard common stopwords.</li>
</ul>
</li>
<li>
<p><strong>Term Discrimination</strong>:</p>
<ul>
<li>It can effectively discriminate between terms that are common across all documents and those that are unique or rare, thus emphasizing the distinctive features of documents.</li>
</ul>
</li>
</ol>
<h3 id="cons-2">Cons</h3>
<ol>
<li><strong>Lack of Semantics</strong>:
<ul>
<li>Like previous methods, TF-IDF doesn&rsquo;t capture semantic relationships between words or consider word order.</li>
</ul>
</li>
<li><strong>Lack of Interpretibility</strong>:
<ul>
<li>The resulting TF-IDF values are not as intuitive or interpretable as raw word counts.</li>
</ul>
</li>
<li><strong>Document Length Bias</strong>:
<ul>
<li>Longer documents may have higher TF-IDF values simply due to their length, potentially leading to biased representations.</li>
</ul>
</li>
<li><strong>Rare Term Issues</strong>:
<ul>
<li>Extremely rare terms or typos may receive very high TF-IDF scores, which can lead to noise in the representation.</li>
</ul>
</li>
</ol>
<p>However, despite its limitations TF-IDF remains a valuable and widely used text representation technique, particularly for tasks that require capturing the importance of words within documents and distinguishing between common and rare terms and also solves issues from earlier methods like BoW or One-Hot Encoding.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this blog, I delved into the world of text vectorization techniques, exploring three fundamental count-based methods: One-Hot encoding, CountVectorizer, and TF-IDF. I dissected these approaches, highlighting their inner workings and discussing the advantages and disadvantages of each.</p>
<p>One-Hot encoding, with its simplicity and binary representation, is a valuable tool for certain tasks. CountVectorizer, on the other hand, provides a straightforward way to capture word frequency, while TF-IDF takes it a step further by considering the importance of words within documents and across a corpus.</p>
<p>In the world of NLP, there&rsquo;s no one-size-fits-all solution. Each method explored today has its strengths and weaknesses, and the art of NLP lies in selecting the right tool for the job. By understanding One-Hot encoding, CountVectorizer, and TF-IDF, one is equipped to make informed decisions that will drive the success of your text analysis projects. However, for more advanced NLP tasks that demand a deeper understanding of word semantics and context, methods like word embeddings and transformer-based models are often preferred which will be discussed later. Also, all the code used for this blog post can be found <a href="Word_Vectors.ipynb">here</a></p>
<h2 id="references">References:</h2>
<ol>
<li><a href="https://www.analyticsvidhya.com/blog/2021/06/part-5-step-by-step-guide-to-master-nlp-text-vectorization-approaches/">Part 5: Step by Step Guide to Master NLP – Word Embedding and Text Vectorization</a></li>
<li><a href="https://neptune.ai/blog/vectorization-techniques-in-nlp-guide">Vectorization Techniques in NLP</a></li>
</ol>
<blockquote>
<p>Photo by <a href="https://projector.tensorflow.org/?_gl=1*1vlx0lq*_ga*MTI1OTYyNTE5NS4xNjYyOTc4NjE4*_ga_W0YLR4190T*MTY5MzkwMjgxMi40LjEuMTY5MzkwMzMyOS4wLjAuMA..">Embedding Projector</a> on <a href="https://www.tensorflow.org/text/tutorials/word2vec">TensorFlow</a></p>
</blockquote>

          </article>
        </div>
      </div>
      <div class="col-sm-12 col-md-12 col-lg-3">
        <div id="stickySideBar" class="sticky-sidebar">
          
          <aside class="toc">
              <h5>
                Table Of Contents
              </h5>
              <div class="toc-content">
                <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#why-do-we-need-word-vectorization">Why Do We Need Word Vectorization?</a></li>
    <li><a href="#one-hot-encoding">One-Hot Encoding</a>
      <ul>
        <li><a href="#pros">Pros</a></li>
        <li><a href="#cons">Cons</a></li>
      </ul>
    </li>
    <li><a href="#countvectorzer-bag-of-words">CountVectorzer (Bag of Words):</a>
      <ul>
        <li><a href="#pros-1">Pros</a></li>
        <li><a href="#cons-1">Cons</a></li>
      </ul>
    </li>
    <li><a href="#tf-idf">TF-IDF</a>
      <ul>
        <li><a href="#pros-2">Pros</a></li>
        <li><a href="#cons-2">Cons</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#references">References:</a></li>
  </ul>
</nav>
              </div>
          </aside>
          

          
          <aside class="tags">
            <h5>Tags</h5>
            <ul class="tags-ul list-unstyled list-inline">
              
              <li class="list-inline-item"><a href="http://localhost:1313/tags/vectorization"
                target="_blank"
              >Vectorization</a></li>
              
              <li class="list-inline-item"><a href="http://localhost:1313/tags/embeddings"
                target="_blank"
              >Embeddings</a></li>
              
              <li class="list-inline-item"><a href="http://localhost:1313/tags/countvectorizer"
                target="_blank"
              >CountVectorizer</a></li>
              
              <li class="list-inline-item"><a href="http://localhost:1313/tags/tf-idf"
                target="_blank"
              >TF-IDF</a></li>
              
              <li class="list-inline-item"><a href="http://localhost:1313/tags/word2vec"
                target="_blank"
              >Word2Vec</a></li>
              
            </ul>
          </aside>
          

          
          <aside class="social">
            <h5>Social</h5>
            <div class="social-content">
              <ul class="list-inline">
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fword-embeddings%2f">
                    <i class="fab fa-linkedin"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://twitter.com/share?text=Unraveling%20the%20Power%20of%20Word%20Vectorization%3a%20From%20Text%20to%20Numbers&url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fword-embeddings%2f">
                    <i class="fab fa-twitter"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://api.whatsapp.com/send?text=Unraveling%20the%20Power%20of%20Word%20Vectorization%3a%20From%20Text%20to%20Numbers: http%3a%2f%2flocalhost%3a1313%2fblogs%2fword-embeddings%2f">
                    <i class="fab fa-whatsapp"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href='mailto:?subject=Unraveling%20the%20Power%20of%20Word%20Vectorization%3a%20From%20Text%20to%20Numbers&amp;body=Check%20out%20this%20site http%3a%2f%2flocalhost%3a1313%2fblogs%2fword-embeddings%2f'>
                    <i class="fa fa-envelope"></i>
                  </a>
                </li>
              </ul>
            </div>
          </aside>
          
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12 col-lg-9 p-4">
        
      </div>
    </div>
  </div>
  <button class="p-2 px-3" onclick="topFunction()" id="topScroll">
    <i class="fas fa-angle-up"></i>
  </button>
</section>


<div class="progress">
  <div id="scroll-progress-bar" class="progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div>
</div>
<Script src="/js/scrollProgressBar.js"></script>


<script>
  var topScroll = document.getElementById("topScroll");
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      topScroll.style.display = "block";
    } else {
      topScroll.style.display = "none";
    }
  }

  function topFunction() {
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
  }

  
  let stickySideBarElem = document.getElementById("stickySideBar");
  let stickyNavBar =  true ;
  if(stickyNavBar) {
    let headerElem = document.getElementById("profileHeader");
    let headerHeight = headerElem.offsetHeight + 15;
    stickySideBarElem.style.top = headerHeight + "px";
  } else {
    stickySideBarElem.style.top = "50px";
  }
</script>


<script src="/js/readingTime.js"></script>



  </div><footer>
    
 
 
<div class="container py-3" id="recent-posts">
    
    
    <div class="h3 text-center text-secondary py-3">
        Recent Posts
    </div>
    <div class="row justify-content-center">
        
        <div class="col-lg-4 col-md-6 pt-2">
            <div class="card h-100">
                
                <div class="card-header">
                    <a href="/blogs/attention-is-all-you-need/">
                        <img src="/projects/attention.png" class="card-img-top" alt="Attention Is All You Need - From where it all started">
                    </a>
                </div>
                
                <div class="card-body bg-transparent p-3 shadow-sm">
                    <a href="/blogs/attention-is-all-you-need/" class="primary-font card-title">
                        <h5 class="card-title bg-transparent" title="Attention Is All You Need - From where it all started">Attention Is All You Need …</h5>
                    </a>
                    <div class="card-text secondary-font">
                        <p>Introduction In the current landscape of Generative Artificial Intelligence (GenAI), new architectures and methodologies emerge with remarkable frequency. According to recent statistics from arXiv, the volume of papers tagged under LLM averages nine submissions daily. To comprehend these …</p>
                    </div>
                </div>
                <div class="mt-auto card-footer">
                    <span class="float-start">Jul 3, 2024</span>
                    <a href="/blogs/attention-is-all-you-need/" class="float-end btn btn-outline-info btn-sm">Read</a>
                </div>
            </div>
        </div>
        
        <div class="col-lg-4 col-md-6 pt-2">
            <div class="card h-100">
                
                <div class="card-header">
                    <a href="/blogs/word-embeddings/">
                        <img src="/blogs/word-embeddings/cover.png" class="card-img-top" alt="Unraveling the Power of Word Vectorization: From Text to Numbers">
                    </a>
                </div>
                
                <div class="card-body bg-transparent p-3 shadow-sm">
                    <a href="/blogs/word-embeddings/" class="primary-font card-title">
                        <h5 class="card-title bg-transparent" title="Unraveling the Power of Word Vectorization: From Text to Numbers">Unraveling the Power of …</h5>
                    </a>
                    <div class="card-text secondary-font">
                        <p>Introduction In the realm of Natural Language Processing (NLP), one of the key challenges is to bridge the gap between the textual world of words and the numerical world of computers. We know that computers only understand in form of numbers (0s and 1s to be precise). So how do we make sense of …</p>
                    </div>
                </div>
                <div class="mt-auto card-footer">
                    <span class="float-start">Sep 5, 2023</span>
                    <a href="/blogs/word-embeddings/" class="float-end btn btn-outline-info btn-sm">Read</a>
                </div>
            </div>
        </div>
        
        <div class="col-lg-4 col-md-6 pt-2">
            <div class="card h-100">
                
                <div class="card-header">
                    <a href="/blogs/hello-world/">
                        <img src="/blogs/hello-world/cover.jpg" class="card-img-top" alt="Embracing Freedom: My Journey to Creating a Personal Blog with Hugo and GitHub Pages">
                    </a>
                </div>
                
                <div class="card-body bg-transparent p-3 shadow-sm">
                    <a href="/blogs/hello-world/" class="primary-font card-title">
                        <h5 class="card-title bg-transparent" title="Embracing Freedom: My Journey to Creating a Personal Blog with Hugo and GitHub Pages">Embracing Freedom: My …</h5>
                    </a>
                    <div class="card-text secondary-font">
                        <p>Introduction In a world dominated by social media platforms and curated content, the idea of having a personal space on the internet has always fascinated me. A place where I can express my thoughts, share my experiences, and have complete control over what goes in and what stays out. That&rsquo;s …</p>
                    </div>
                </div>
                <div class="mt-auto card-footer">
                    <span class="float-start">Sep 4, 2023</span>
                    <a href="/blogs/hello-world/" class="float-end btn btn-outline-info btn-sm">Read</a>
                </div>
            </div>
        </div>
        
    </div>
</div>

<div class="text-center pt-2">
    
    <span class="px-1">
        <a href="https://github.com/sarthak247" aria-label="github">
            <svg xmlns="http://www.w3.org/2000/svg" width="2.7em" height="2.7em" viewBox="0 0 1792 1792">
                <path
                    d="M522 1352q-8 9-20-3-13-11-4-19 8-9 20 3 12 11 4 19zm-42-61q9 12 0 19-8 6-17-7t0-18q9-7 17 6zm-61-60q-5 7-13 2-10-5-7-12 3-5 13-2 10 5 7 12zm31 34q-6 7-16-3-9-11-2-16 6-6 16 3 9 11 2 16zm129 112q-4 12-19 6-17-4-13-15t19-7q16 5 13 16zm63 5q0 11-16 11-17 2-17-11 0-11 16-11 17-2 17 11zm58-10q2 10-14 14t-18-8 14-15q16-2 18 9zm964-956v960q0 119-84.5 203.5t-203.5 84.5h-224q-16 0-24.5-1t-19.5-5-16-14.5-5-27.5v-239q0-97-52-142 57-6 102.5-18t94-39 81-66.5 53-105 20.5-150.5q0-121-79-206 37-91-8-204-28-9-81 11t-92 44l-38 24q-93-26-192-26t-192 26q-16-11-42.5-27t-83.5-38.5-86-13.5q-44 113-7 204-79 85-79 206 0 85 20.5 150t52.5 105 80.5 67 94 39 102.5 18q-40 36-49 103-21 10-45 15t-57 5-65.5-21.5-55.5-62.5q-19-32-48.5-52t-49.5-24l-20-3q-21 0-29 4.5t-5 11.5 9 14 13 12l7 5q22 10 43.5 38t31.5 51l10 23q13 38 44 61.5t67 30 69.5 7 55.5-3.5l23-4q0 38 .5 103t.5 68q0 22-11 33.5t-22 13-33 1.5h-224q-119 0-203.5-84.5t-84.5-203.5v-960q0-119 84.5-203.5t203.5-84.5h960q119 0 203.5 84.5t84.5 203.5z" />

                <metadata>
                    <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                        xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:dc="http://purl.org/dc/elements/1.1/">
                        <rdf:Description about="https://iconscout.com/legal#licenses"
                            dc:title="Github, Online, Project, Hosting, Square"
                            dc:description="Github, Online, Project, Hosting, Square" dc:publisher="Iconscout"
                            dc:date="2016-12-14" dc:format="image/svg+xml" dc:language="en">
                            <dc:creator>
                                <rdf:Bag>
                                    <rdf:li>Font Awesome</rdf:li>
                                </rdf:Bag>
                            </dc:creator>
                        </rdf:Description>
                    </rdf:RDF>
                </metadata>
            </svg>
        </a>
    </span>
    

    
    <span class="px-1">
        <a href="https://linkedin.com/in/sarthak247/" aria-label="linkedin">
            <svg xmlns="http://www.w3.org/2000/svg" width='2.4em' height='2.4em' fill="#fff" aria-label="LinkedIn"
                viewBox="0 0 512 512">
                <rect width="512" height="512" fill="#0077b5" rx="15%" />
                <circle cx="142" cy="138" r="37" />
                <path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198" />
                <path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
        </a>
    </span>
    

    
    <a href="https://x.com/sarthak2407" aria-label="twitter">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="48px" height="48px">
            <path fill="#03a9f4"
                d="M42,37c0,2.762-2.239,5-5,5H11c-2.762,0-5-2.238-5-5V11c0-2.762,2.238-5,5-5h26c2.761,0,5,2.238,5,5 V37z" />
            <path fill="#fff"
                d="M36,17.12c-0.882,0.391-1.999,0.758-3,0.88c1.018-0.604,2.633-1.862,3-3 c-0.951,0.559-2.671,1.156-3.793,1.372C31.311,15.422,30.033,15,28.617,15C25.897,15,24,17.305,24,20v2c-4,0-7.9-3.047-10.327-6 c-0.427,0.721-0.667,1.565-0.667,2.457c0,1.819,1.671,3.665,2.994,4.543c-0.807-0.025-2.335-0.641-3-1c0,0.016,0,0.036,0,0.057 c0,2.367,1.661,3.974,3.912,4.422C16.501,26.592,16,27,14.072,27c0.626,1.935,3.773,2.958,5.928,3c-1.686,1.307-4.692,2-7,2 c-0.399,0-0.615,0.022-1-0.023C14.178,33.357,17.22,34,20,34c9.057,0,14-6.918,14-13.37c0-0.212-0.007-0.922-0.018-1.13 C34.95,18.818,35.342,18.104,36,17.12" />
        </svg>
    </a>
    

    

    
</div><div class="container py-4">
    <div class="row justify-content-center">
        <div class="col-md-4 text-center">
            
                <div class="pb-2">
                    <a href="http://localhost:1313/" title="Sarthak Thakur">
                        <img alt="Footer logo" src="./favicon.png"
                            height="40px" width="40px">
                    </a>
                </div>
            
            &copy; 2024  All rights reserved
            <div class="text-secondary">
                Made with
                <span class="text-danger">
                    &#10084;
                </span>
                and
                <a href="https://github.com/gurusabarish/hugo-profile" target="_blank"
                    title="Designed and developed by gurusabarish">
                    Hugo Profile
                </a>
            </div>
        </div>
    </div>
</div>
</footer><script src="/bootstrap-5/js/bootstrap.bundle.min.js"></script>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

    var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
    var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
        return new bootstrap.Tooltip(tooltipTriggerEl)
    })

</script>


    <script src="/js/search.js"></script>





<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js" integrity="sha384-M5jmNxKC9EVnuqeMwRHvFuYUE8Hhp0TgBruj/GZRkYtiMrCRgH7yvv5KY+Owi7TW" crossorigin="anonymous"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
      }
    });
</script>








  <section id="search-content" class="py-2">
    <div class="container" id="search-results"></div>
  </section>
</body>

</html>
